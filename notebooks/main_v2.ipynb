{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yCiEkXjbnyQ6",
        "VN35Uv0ghrxH",
        "ePDtUBOenrEJ",
        "Odgmww0UntjI",
        "vQWzA65pWmBd",
        "zAhFE7Qoj6P-",
        "_DV6UQLJkI0j",
        "WgD9QKtt1F95"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b90610a642ee4c8189c795e7d6e25463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a0b786220114d8b81eb0af1bc7c431a",
              "IPY_MODEL_789e635f556141c59e97a63b4e2f24bc"
            ],
            "layout": "IPY_MODEL_77e4fbf83c6e49d2a21996681b6bca53"
          }
        },
        "4a0b786220114d8b81eb0af1bc7c431a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0e18de9d7314d69ac4733e8d7ea8c06",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffeef48cf6e34a3eb78950945ae3c4f8",
            "value": 213450
          }
        },
        "789e635f556141c59e97a63b4e2f24bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd4dc1d4d6c9408a82f50f92c728ae22",
            "placeholder": "​",
            "style": "IPY_MODEL_5b181305db2f4855b9110fd3e8699d6f",
            "value": "100% 208k/208k [00:00&lt;00:00, 1.21MB/s]"
          }
        },
        "77e4fbf83c6e49d2a21996681b6bca53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e18de9d7314d69ac4733e8d7ea8c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffeef48cf6e34a3eb78950945ae3c4f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "bd4dc1d4d6c9408a82f50f92c728ae22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b181305db2f4855b9110fd3e8699d6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ae517a7b40b42918a19ce1493de2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_777adc688f8d4d368b325c192f0a5bc8",
              "IPY_MODEL_08cd13df222d404b840ff4fcdf3bb413"
            ],
            "layout": "IPY_MODEL_dd32f2d8001a4039a07e26c64b11f74a"
          }
        },
        "777adc688f8d4d368b325c192f0a5bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f5fe87efb94a4f850881bbd06fe28e",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_684a9fe4a4ba479793e6b486d92f7dd1",
            "value": 29
          }
        },
        "08cd13df222d404b840ff4fcdf3bb413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4961c1da07a84f14a743f405e02cffe8",
            "placeholder": "​",
            "style": "IPY_MODEL_051cb5f3354b494384e29745a0186c4c",
            "value": "100% 29.0/29.0 [00:00&lt;00:00, 278B/s]"
          }
        },
        "dd32f2d8001a4039a07e26c64b11f74a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f5fe87efb94a4f850881bbd06fe28e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "684a9fe4a4ba479793e6b486d92f7dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "4961c1da07a84f14a743f405e02cffe8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "051cb5f3354b494384e29745a0186c4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f7ac259784243a8ab66da66547741ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_97565339efc04846b5b4f409e2c915b0",
              "IPY_MODEL_1f18505cf9f149ab84a8f1832425fa29"
            ],
            "layout": "IPY_MODEL_d6ff14fb98614a08a9ba5e4f03f153c1"
          }
        },
        "97565339efc04846b5b4f409e2c915b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading",
            "description_tooltip": null,
            "layout": "IPY_MODEL_16ce3e0c21af493c9733481885e868ce",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_81b77dc6330b40f9b0e36eb531a6ef2c",
            "value": 570
          }
        },
        "1f18505cf9f149ab84a8f1832425fa29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a03c9f0b68e541d395fef38989406e18",
            "placeholder": "​",
            "style": "IPY_MODEL_c8c046b196d54b529536c00fe256a71a",
            "value": "100% 570/570 [00:00&lt;00:00, 5.06kB/s]"
          }
        },
        "d6ff14fb98614a08a9ba5e4f03f153c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ce3e0c21af493c9733481885e868ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b77dc6330b40f9b0e36eb531a6ef2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "a03c9f0b68e541d395fef38989406e18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c046b196d54b529536c00fe256a71a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7218cb22897c4ce48f66a074be06e8ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0e2700420b54adaa1447d7be40bc5b2",
              "IPY_MODEL_04977569a7e4478088881026bd10094f"
            ],
            "layout": "IPY_MODEL_e40bb1160c0848e99dd37038332b1160"
          }
        },
        "e0e2700420b54adaa1447d7be40bc5b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "IntProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4d1d9967f8a4cda8ce6d325749044ec",
            "max": 435779157,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d562e31adbf34e13a2542ad6ced053db",
            "value": 435779157
          }
        },
        "04977569a7e4478088881026bd10094f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1103fb2498f4958a7fc251af068671a",
            "placeholder": "​",
            "style": "IPY_MODEL_c4ae7d47374f4c4fa37320dcc8041a6b",
            "value": "100% 416M/416M [00:16&lt;00:00, 27.0MB/s]"
          }
        },
        "e40bb1160c0848e99dd37038332b1160": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d1d9967f8a4cda8ce6d325749044ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d562e31adbf34e13a2542ad6ced053db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "d1103fb2498f4958a7fc251af068671a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ae7d47374f4c4fa37320dcc8041a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Ir4WVRpLpV3Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## github and weights"
      ],
      "metadata": {
        "id": "UGKVh-Vin0EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "!rm -r /content/FinTabParse\n",
        "!git clone https://github.com/MeMihir/FinTabParse.git\n",
        "!cd FinTabParse/ && git checkout trans2-test"
      ],
      "metadata": {
        "id": "SP2K2T0wlxI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58236a92-6271-443b-e641-b4b73fbd4ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "rm: cannot remove '/content/FinTabParse': No such file or directory\n",
            "Cloning into 'FinTabParse'...\n",
            "remote: Enumerating objects: 2694, done.\u001b[K\n",
            "remote: Counting objects: 100% (2694/2694), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2556/2556), done.\u001b[K\n",
            "remote: Total 2694 (delta 119), reused 2672 (delta 99), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2694/2694), 19.61 MiB | 15.82 MiB/s, done.\n",
            "Resolving deltas: 100% (119/119), done.\n",
            "Branch 'trans2-test' set up to track remote branch 'trans2-test' from 'origin'.\n",
            "Switched to a new branch 'trans2-test'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd FinTabParse/utils/ && pip install -e ./transformers-2.6.0/"
      ],
      "metadata": {
        "id": "OZs1Zj6CIAJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8730c19-75e9-4a70-8ecd-2c62a22e8be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/FinTabParse/utils/transformers-2.6.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (1.21.6)\n",
            "Collecting tokenizers==0.5.2\n",
            "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.23.5-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 52.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (3.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.6.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 41.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.27.0,>=1.26.5\n",
            "  Downloading botocore-1.26.5-py3-none-any.whl (8.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8 MB 47.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.27.0,>=1.26.5->boto3->transformers==2.6.0) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 10.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.27.0,>=1.26.5->boto3->transformers==2.6.0) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.6.0) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.6.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.6.0) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=1ba14135558a9d58f67ce28bc931e5859873c0a01ffe87135e40e39f33806245\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, tokenizers, sentencepiece, sacremoses, boto3, transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Running setup.py develop for transformers\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.23.5 botocore-1.26.5 jmespath-1.0.0 s3transfer-0.5.2 sacremoses-0.0.53 sentencepiece-0.1.96 tokenizers-0.5.2 transformers-2.6.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle kernels output mihirpavuskar/tat-qa-train -p /content/FinTabParse/models/"
      ],
      "metadata": {
        "id": "NQypW9-E4GNn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9c59e1-c55d-46d3-b206-68e2e4d670fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/HEAD\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/config\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/description\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/applypatch-msg.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/commit-msg.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/fsmonitor-watchman.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/post-update.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-applypatch.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-commit.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-merge-commit.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-push.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-rebase.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/pre-receive.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/prepare-commit-msg.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/hooks/update.sample\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/index\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/info/exclude\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/logs/HEAD\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/logs/refs/heads/master\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/logs/refs/remotes/origin/HEAD\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/objects/pack/pack-4c0d07a2e38c2e873bf86fa2af856d00144947f3.idx\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/objects/pack/pack-4c0d07a2e38c2e873bf86fa2af856d00144947f3.pack\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/packed-refs\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/refs/heads/master\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.git/refs/remotes/origin/HEAD\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/.gitignore\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/LICENSE\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/README.md\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/__pycache__/tatqa_eval.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/__pycache__/tatqa_metric.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/__pycache__/tatqa_utils.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/checkpoint/args.json\n",
            "tcmalloc: large alloc 2885328896 bytes == 0xd3e34000 @  0x7f68d20081e7 0x4a3940 0x5b438c 0x5b46f7 0x59afff 0x515655 0x59a257 0x570bf0 0x511ee1 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x511e2c 0x549576 0x4bca8a\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/checkpoint/checkpoint_best.ot\n",
            "tcmalloc: large alloc 1446887424 bytes == 0x17fe4c000 @  0x7f68d20081e7 0x4a3940 0x5b438c 0x5b46f7 0x59afff 0x515655 0x59a257 0x570bf0 0x511ee1 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x511e2c 0x549576 0x4bca8a\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/checkpoint/checkpoint_best.pt\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/checkpoint/train.log\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_raw/tatqa_dataset_dev.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_raw/tatqa_dataset_test.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_raw/tatqa_dataset_train.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/roberta.large/config.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/roberta.large/merges.txt\n",
            "tcmalloc: large alloc 1425948672 bytes == 0xd28b4000 @  0x7f68d20081e7 0x4a3940 0x5b438c 0x5b46f7 0x59afff 0x515655 0x59a257 0x570bf0 0x511ee1 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x59c019 0x595ef6 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x511e2c 0x549576 0x4bca8a\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/roberta.large/pytorch_model.bin\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/roberta.large/vocab.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/tatqa_dataset_dev.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/dataset_tagop/tatqa_dataset_train.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/assets/next.jpeg\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/assets/tatqa-sample.png\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/Lobster-Regular.ttf\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/OFL.txt\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/glyphicons-halflings-regular.eot\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/glyphicons-halflings-regular.svg\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/glyphicons-halflings-regular.ttf\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/glyphicons-halflings-regular.woff\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/fonts/glyphicons-halflings-regular.woff2\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/index.html\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/scripts/bootstrap.min.js\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/scripts/jquery-3.2.1.min.js\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/scripts/jquery.easing.min.js\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/scripts/scrolling-nav.js\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/scripts/show-json.js\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/styles/bootstrap.min.css\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/styles/common.css\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/docs/styles/show-json.css\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/requirement.txt\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/sample_prediction.json\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/__pycache__/__init__.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/__pycache__/options.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/cache/tagop_roberta_cached_dev.pkl\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/cache/tagop_roberta_cached_train.pkl\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__pycache__/__init__.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__pycache__/data_util.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__pycache__/file_utils.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__pycache__/tatqa_batch_gen.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/__pycache__/tatqa_dataset.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/data_util.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/file_utils.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/tatqa_batch_gen.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/tatqa_dataset.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/__pycache__/__init__.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/__pycache__/logging.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/dummy_flax_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/dummy_pt_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/dummy_sentencepiece_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/dummy_tf_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/dummy_tokenizers_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/hp_naming.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/logging.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/notebook.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/data/utils/sentencepiece_model_pb2.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/options.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/predictor.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/prepare_dataset.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__pycache__/__init__.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__pycache__/model.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__pycache__/modeling_tagop.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__pycache__/optimizer.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/__pycache__/util.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/model.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/modeling_tagop.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/optimizer.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/__pycache__/__init__.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/__pycache__/allennlp.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/__pycache__/util.cpython-37.pyc\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/allennlp.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/tools/util.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/util.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/__init__.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/dummy_flax_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/dummy_pt_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/dummy_sentencepiece_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/dummy_tf_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/dummy_tokenizers_objects.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/hp_naming.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/logging.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/notebook.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/tagop/utils/sentencepiece_model_pb2.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tag_op/trainer.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tatqa_eval.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tatqa_metric.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tatqa_metric_test.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tatqa_utils.py\n",
            "Output file downloaded to /content/FinTabParse/models/TAT-QA/tatqa_utils_test.py\n",
            "Kernel log downloaded to /content/FinTabParse/models/tat-qa-train.log \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !cd /content/FinTabParse/models/ && git clone https://github.com/wenhuchen/HybridQA.git\n",
        "# !cd /content/FinTabParse/models/HybridQA && wget https://hybridqa.s3-us-west-2.amazonaws.com/models.zip && unzip models.zip\n",
        "!cd /content/FinTabParse/models/HybridR && wget https://hybridqa.s3-us-west-2.amazonaws.com/models.zip && unzip models.zip"
      ],
      "metadata": {
        "id": "qAPYraZ4mMr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57267f44-68a4-4c8f-b26c-219b7807dc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-22 07:01:06--  https://hybridqa.s3-us-west-2.amazonaws.com/models.zip\n",
            "Resolving hybridqa.s3-us-west-2.amazonaws.com (hybridqa.s3-us-west-2.amazonaws.com)... 52.218.170.58\n",
            "Connecting to hybridqa.s3-us-west-2.amazonaws.com (hybridqa.s3-us-west-2.amazonaws.com)|52.218.170.58|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6170000875 (5.7G) [application/zip]\n",
            "Saving to: ‘models.zip’\n",
            "\n",
            "models.zip          100%[===================>]   5.75G  35.5MB/s    in 2m 48s  \n",
            "\n",
            "2022-05-22 07:03:55 (34.9 MB/s) - ‘models.zip’ saved [6170000875/6170000875]\n",
            "\n",
            "Archive:  models.zip\n",
            "   creating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/\n",
            "  inflating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/config.json  \n",
            "  inflating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/pytorch_model.bin  \n",
            "  inflating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/training_args.bin  \n",
            "  inflating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/vocab.txt  \n",
            "  inflating: stage1/2020_10_03_22_47_34/checkpoint-epoch2/special_tokens_map.json  \n",
            " extracting: stage1/2020_10_03_22_47_34/checkpoint-epoch2/tokenizer_config.json  \n",
            "   creating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/\n",
            "  inflating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/config.json  \n",
            "  inflating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/pytorch_model.bin  \n",
            "  inflating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/training_args.bin  \n",
            "  inflating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/vocab.txt  \n",
            "  inflating: stage2/2020_10_03_22_50_31/checkpoint-epoch2/special_tokens_map.json  \n",
            " extracting: stage2/2020_10_03_22_50_31/checkpoint-epoch2/tokenizer_config.json  \n",
            "   creating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/\n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/config.json  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/scheduler.pt  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/pytorch_model.bin  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/training_args.bin  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/vocab.txt  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/special_tokens_map.json  \n",
            " extracting: stage3/2020_10_03_22_51_12/checkpoint-epoch3/tokenizer_config.json  \n",
            "  inflating: stage3/2020_10_03_22_51_12/checkpoint-epoch3/optimizer.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp /content/drive/MyDrive/Capstone/Table_Parsing_QA/models/model_f-1_e-3.pt /content/FinTabParse/weights/questions_classifier"
      ],
      "metadata": {
        "id": "3MAMEJWXpYdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## installs"
      ],
      "metadata": {
        "id": "yCiEkXjbnyQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install tqdm\n",
        "!pip install fuzzywuzzy\n",
        "!pip install dateparser"
      ],
      "metadata": {
        "id": "TQIOl8S51BbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1447c7d-b84b-401d-e873-792a1f526b05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 15.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n",
            "Collecting dateparser\n",
            "  Downloading dateparser-1.1.1-py2.py3-none-any.whl (288 kB)\n",
            "\u001b[K     |████████████████████████████████| 288 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser) (1.5.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from dateparser) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from dateparser) (2022.1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27,<2022.3.15 in /usr/local/lib/python3.7/dist-packages (from dateparser) (2019.12.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil->dateparser) (1.15.0)\n",
            "Installing collected packages: dateparser\n",
            "Successfully installed dateparser-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd ./FinTabParse/ && pip install -r requirement.txt\n",
        "!pip install https://data.pyg.org/whl/torch-1.7.0%2Bcu102/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DBurVzwh6cG",
        "outputId": "1e8fac28-b163-4241-aeb9-8b626a64c1d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-scatter==2.0.7\n",
            "  Downloading https://data.pyg.org/whl/torch-1.7.0%2Bcu102/torch_scatter-2.0.7-cp37-cp37m-linux_x86_64.whl (2.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7 MB 2.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "xa9ZTm5xE6LD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHWJxXWjO__0",
        "outputId": "cda27acf-817b-46f1-e52d-788f566a2a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -U transformers===4.0.0"
      ],
      "metadata": {
        "id": "tSu768NU_YV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code"
      ],
      "metadata": {
        "id": "VN35Uv0ghrxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/FinTabParse\n",
        "# !rm -r /content/FinTabParse/inputs/*"
      ],
      "metadata": {
        "id": "-DTvy4RAhs7X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5bdd22b-f6e7-4eae-cf0e-a4194e136969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/FinTabParse'\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## main.py"
      ],
      "metadata": {
        "id": "ePDtUBOenrEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import torch\n",
        "\n",
        "from transformers import  BertTokenizer, AlbertTokenizer, AlbertForQuestionAnswering\n",
        "from models.questions_classifier import BertClassifier\n",
        "\n",
        "from utils.file_handling import file_to_list, json_to_dict, dict_to_json\n",
        "from preprocessing import tagop_preprocessing, hybridr_preprocessing\n",
        "from models.HybridR.preprocessing import preprocessing_main\n",
        "\n",
        "def paragraph_qa_model(questions, text):\n",
        "\tAlTokenizer = AlbertTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
        "\tAlQA = AlbertForQuestionAnswering.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
        "\tanswers = []\n",
        "\n",
        "\tfor que in questions:\n",
        "\t\tinputs = AlTokenizer(que, text, return_tensors=\"pt\")\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\t\toutputs = AlQA(**inputs, return_dict=True)\n",
        "\t\t\n",
        "\t\tanswer_start_index = outputs.start_logits.argmax()\n",
        "\t\tanswer_end_index = outputs.end_logits.argmax()\n",
        "\t\tpredict_answer_tokens = inputs.input_ids[0, answer_start_index : answer_end_index + 1]\n",
        "\t\tanswers.append(AlTokenizer.decode(predict_answer_tokens))\n",
        "\n",
        "\treturn answers\n",
        "\n",
        "\n",
        "def question_classifier_model(questions, model_path):\n",
        "\ttokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        " \t\n",
        "\tquestion_classifier = BertClassifier()\n",
        "\tquestion_classifier.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
        " \n",
        "\tquestion_infs = list(map(lambda question_input: tokenizer(question_input, padding='max_length', max_length = 512, truncation=True, return_tensors=\"pt\"), questions))\n",
        "\tquestion_preds = []\n",
        "\n",
        "\tfor que_inf in question_infs:\n",
        "\t\tquestion_id = que_inf['input_ids']\n",
        "\t\tquestion_mask = que_inf['attention_mask'].squeeze(1)\n",
        "\t\tpred = question_classifier(question_id, question_mask)\n",
        "\t\tquestion_preds.append(pred.argmax(dim=1).numpy()[0])\n",
        "\t\n",
        "\treturn question_preds\n"
      ],
      "metadata": {
        "id": "tNTTlMsijib3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "39fb0dc0-7227-4fec-bd1f-64430bd7cbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-68096e93ed9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertForQuestionAnswering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestions_classifier\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_handling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_to_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_to_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_to_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def prepare_hybridR_data(questions, paragraphs, table, question_preds):\n",
        "  hybridR_questions = list(map(lambda x: x[1], filter(lambda x: x[0]==0, zip(question_preds, questions))))\n",
        "  hybirdR_paragraphs, hybirdR_ques, hybirdR_table = hybridr_preprocessing(table, paragraphs, hybridR_questions)\n",
        "\n",
        "  os.makedirs('models/HybridR/test_inputs/', exist_ok=True)\n",
        "  dict_to_json(hybirdR_ques, 'models/HybridR/test_inputs/test.json')\n",
        "\n",
        "  os.makedirs('inputs/request_tok', exist_ok=True)\n",
        "  dict_to_json(hybirdR_paragraphs, 'inputs/request_tok/table_0.json')\n",
        "\n",
        "  os.makedirs('inputs/tables_tok', exist_ok=True)\n",
        "  dict_to_json(hybirdR_table, 'inputs/tables_tok/table_0.json')\n",
        "\n",
        "  del hybirdR_ques\n",
        "  del hybirdR_paragraphs\n",
        "  del hybirdR_table\n",
        "\n",
        "  preprocessing_main()\n",
        "\n",
        "  !rm -r /content/FinTabParse/models/HybridR/WikiTables-WithLinks/\n",
        "  !mkdir /content/FinTabParse/models/HybridR/WikiTables-WithLinks/\n",
        "  !cp -r /content/FinTabParse/inputs/request_tok /content/FinTabParse/models/HybridR/WikiTables-WithLinks/\n",
        "  !cp -r /content/FinTabParse/inputs/tables_tok /content/FinTabParse/models/HybridR/WikiTables-WithLinks/\n",
        "  !cp -r /content/FinTabParse/inputs/tables_tmp /content/FinTabParse/models/HybridR/WikiTables-WithLinks/\n"
      ],
      "metadata": {
        "id": "jhAegJHOCzHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## run code"
      ],
      "metadata": {
        "id": "Odgmww0UntjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/FinTabParse/tests/test2/* /content/FinTabParse/inputs"
      ],
      "metadata": {
        "id": "9KOlg-nFo6n4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc49a08d-a1ef-44f1-9bee-7cae91292d7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory '/content/FinTabParse/tests/test2/outputs'\n",
            "cp: -r not specified; omitting directory '/content/FinTabParse/tests/test2/outputs2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### input & preprocessing"
      ],
      "metadata": {
        "id": "vQWzA65pWmBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.file_handling import read_inputs\n",
        "from preprocessing import  prepare_AlQA_data, prepare_tagop_data\n",
        "\n",
        "AlQA = \"\"\n",
        "questions, paragraphs, table = read_inputs()\n",
        "question_preds = question_classifier_model(questions, '/content/FinTabParse/weights/questions_classifier')\n",
        "\n",
        "dataclass = \"para\" if len(table)==0 else \"tab_para\"\n",
        "\n",
        "if dataclass == \"para\":\n",
        "  AlQA = prepare_AlQA_data(paragraphs)\n",
        "else:\n",
        "  prepare_hybridR_data(questions, paragraphs, table, question_preds)\n",
        "# prepare_hybridR_data(questions, paragraphs, table, question_preds)\n",
        "tag_op_input = prepare_tagop_data(questions, paragraphs, table, question_preds)"
      ],
      "metadata": {
        "id": "_HPHEMutjmIH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "b90610a642ee4c8189c795e7d6e25463",
            "4a0b786220114d8b81eb0af1bc7c431a",
            "789e635f556141c59e97a63b4e2f24bc",
            "77e4fbf83c6e49d2a21996681b6bca53",
            "c0e18de9d7314d69ac4733e8d7ea8c06",
            "ffeef48cf6e34a3eb78950945ae3c4f8",
            "bd4dc1d4d6c9408a82f50f92c728ae22",
            "5b181305db2f4855b9110fd3e8699d6f",
            "4ae517a7b40b42918a19ce1493de2258",
            "777adc688f8d4d368b325c192f0a5bc8",
            "08cd13df222d404b840ff4fcdf3bb413",
            "dd32f2d8001a4039a07e26c64b11f74a",
            "19f5fe87efb94a4f850881bbd06fe28e",
            "684a9fe4a4ba479793e6b486d92f7dd1",
            "4961c1da07a84f14a743f405e02cffe8",
            "051cb5f3354b494384e29745a0186c4c",
            "1f7ac259784243a8ab66da66547741ca",
            "97565339efc04846b5b4f409e2c915b0",
            "1f18505cf9f149ab84a8f1832425fa29",
            "d6ff14fb98614a08a9ba5e4f03f153c1",
            "16ce3e0c21af493c9733481885e868ce",
            "81b77dc6330b40f9b0e36eb531a6ef2c",
            "a03c9f0b68e541d395fef38989406e18",
            "c8c046b196d54b529536c00fe256a71a",
            "7218cb22897c4ce48f66a074be06e8ea",
            "e0e2700420b54adaa1447d7be40bc5b2",
            "04977569a7e4478088881026bd10094f",
            "e40bb1160c0848e99dd37038332b1160",
            "c4d1d9967f8a4cda8ce6d325749044ec",
            "d562e31adbf34e13a2542ad6ced053db",
            "d1103fb2498f4958a7fc251af068671a",
            "c4ae7d47374f4c4fa37320dcc8041a6b"
          ]
        },
        "outputId": "4ec5ffea-3f53-4f79-93cb-6b2ae6ae4147"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b90610a642ee4c8189c795e7d6e25463"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=29, style=ProgressStyle(description_width='…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4ae517a7b40b42918a19ce1493de2258"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=570, style=ProgressStyle(description_width=…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f7ac259784243a8ab66da66547741ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7218cb22897c4ce48f66a074be06e8ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'question_id': 'que_0', 'question': \"What is the name of the employee who's job title is CNC Operator?,\", 'table_id': 'table_0', 'question_postag': 'WP VBZ DT NN IN DT NN WP VBZ NN NN VBZ NNP NNP . ,'}, {'question_id': 'que_1', 'question': \"What is the name of the employee who's job title is computer numerical controlled operator?,\", 'table_id': 'table_0', 'question_postag': 'WP VBZ DT NN IN DT NN WP VBZ NN NN VBZ NN JJ VBD NN . ,'}, {'question_id': 'que_2', 'question': \"What is the major of the employee who's job title is computer numerical controlled operator?,\", 'table_id': 'table_0', 'question_postag': 'WP VBZ DT JJ IN DT NN WP VBZ NN NN VBZ NN JJ VBD NN . ,'}, {'question_id': 'que_3', 'question': 'Which university did the employee with the highest salary graduate from?,', 'table_id': 'table_0', 'question_postag': 'NNP NN VBD DT NN IN DT JJS JJ NN IN . ,'}, {'question_id': 'que_4', 'question': 'How many employees use gmail for thier email address?,', 'table_id': 'table_0', 'question_postag': 'WRB JJ NNS VBP NN IN JJR NN NN . ,'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### processing"
      ],
      "metadata": {
        "id": "zAhFE7Qoj6P-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AlQA_pred = []\n",
        "if len(table)!=0:\n",
        "  !cd /content/FinTabParse/models/HybridR && CUDA_VISIBLE_DEVICES=0 python train_stage12.py --stage1_model stage1/2020_10_03_22_47_34/checkpoint-epoch2 --stage2_model stage2/2020_10_03_22_50_31/checkpoint-epoch2/ --do_lower_case --predict_file preprocessed_test/test_inputs.json --do_eval --option stage12 --model_name_or_path  bert-large-uncased\n",
        "  !cd /content/FinTabParse/models/HybridR && CUDA_VISIBLE_DEVICES=0 python train_stage3.py --model_name_or_path stage3/2020_10_03_22_51_12/checkpoint-epoch3/ --do_stage3   --do_lower_case  --predict_file predictions.intermediate.json --per_gpu_train_batch_size 12  --max_seq_length 384   --doc_stride 128 --threads 8\n",
        "else:\n",
        "  AlQA_pred = paragraph_qa_model(questions, AlQA)"
      ],
      "metadata": {
        "id": "vZ_slnjMbTjP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "349462c0-8a62-4baf-ff41-08de2d3f7513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "05/22/2022 06:31:15 - INFO - transformers2.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json from cache at /tmp/6dfaed860471b03ab5b9acb6153bea82b6632fb9bbe514d3fff050fe1319ee6d.788fed32bb8481a9b15ce726d41c53d5d5066b04c667e34ce3a7a3826d1573d8\n",
            "05/22/2022 06:31:15 - INFO - transformers2.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "05/22/2022 06:31:15 - INFO - transformers2.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /tmp/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "05/22/2022 06:31:15 - INFO - transformers2.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin from cache at /tmp/54da47087cc86ce75324e4dc9bbb5f66c6e83a7c6bd23baea8b489acc8d09aa4.4d5343a4b979c4beeaadef17a0453d1bb183dd9b084f58b84c7cc781df343ae6\n",
            "Traceback (most recent call last):\n",
            "  File \"train_stage12.py\", line 680, in <module>\n",
            "    main()\n",
            "  File \"train_stage12.py\", line 504, in main\n",
            "    filter_model.to(args.device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 612, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 381, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 610, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 172, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: No CUDA GPUs are available\n",
            "05/22/2022 06:31:40 - INFO - transformers2.configuration_utils -   loading configuration file stage3/2020_10_03_22_51_12/checkpoint-epoch3/config.json\n",
            "05/22/2022 06:31:40 - INFO - transformers2.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForQuestionAnswering\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   Model name 'stage3/2020_10_03_22_51_12/checkpoint-epoch3/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'stage3/2020_10_03_22_51_12/checkpoint-epoch3/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   Didn't find file stage3/2020_10_03_22_51_12/checkpoint-epoch3/added_tokens.json. We won't load it.\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   loading file stage3/2020_10_03_22_51_12/checkpoint-epoch3/vocab.txt\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   loading file None\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   loading file stage3/2020_10_03_22_51_12/checkpoint-epoch3/special_tokens_map.json\n",
            "05/22/2022 06:31:40 - INFO - transformers2.tokenization_utils -   loading file stage3/2020_10_03_22_51_12/checkpoint-epoch3/tokenizer_config.json\n",
            "05/22/2022 06:31:40 - INFO - transformers2.modeling_utils -   loading weights file stage3/2020_10_03_22_51_12/checkpoint-epoch3/pytorch_model.bin\n",
            "Traceback (most recent call last):\n",
            "  File \"train_stage3.py\", line 1153, in <module>\n",
            "    main()\n",
            "  File \"train_stage3.py\", line 1065, in main\n",
            "    model.to(args.device)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 612, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 359, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 381, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 610, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() else None, non_blocking)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\", line 172, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: No CUDA GPUs are available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/FinTabParse/models/TAT-QA && PYTHONPATH=$PYTHONPATH:$(pwd):$(pwd)/tag_op python tag_op/prepare_dataset.py --mode dev\n",
        "!cd /content/FinTabParse/models/TAT-QA && PYTHONPATH=$PYTHONPATH:$(pwd) python tag_op/predictor.py --data_dir tag_op/cache/ --test_data_dir tag_op/cache/ --save_dir tag_op/ --eval_batch_size 32 --model_path ./checkpoint --encoder roberta"
      ],
      "metadata": {
        "id": "84OjFW_Io3cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d894fa8-3b4a-4001-e4e7-c22443a4b58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== NOTE ====: encoder:roberta, mode:dev\n",
            "Reading file at %s ./dataset_tagop/tatqa_dataset_dev.json\n",
            "Reading the tatqa dataset\n",
            "100% 1/1 [00:00<00:00,  1.62it/s]\n",
            "{'Span-in-text': 0, 'Cell-in-table': 0, 'Spans': 0, 'Sum': 0, 'Count': 0, 'Average': 0, 'Multiplication': 0, 'Division': 0, 'Difference': 0, 'Change ratio': 0}\n",
            "{'': 10, 'thousand': 0, 'million': 0, 'billion': 0, 'percent': 0}\n",
            "0\n",
            "Save data to ./tag_op/cache/tagop_roberta_cached_dev.pkl.\n",
            "Namespace(ablation_mode=0, bert_learning_rate=None, bert_weight_decay=None, cuda=False, data_dir='tag_op/cache/', encoder='roberta', eval_batch_size=32, gpu_num=0, log_file='train.log', mode=1, model_path='./checkpoint', op_mode=0, roberta_model='dataset_tagop/roberta.large', save_dir='tag_op/', test_data_dir='tag_op/cache/')\n",
            "tag_op/cache/tagop_roberta_cached_dev.pkl\n",
            "Load data from tagop_roberta_cached_dev.pkl.\n",
            "Load data size 10.\n",
            "Some weights of the model checkpoint at dataset_tagop/roberta.large were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "05/22/2022 06:32:29 Below are the result on Dev set...\n",
            "100% 1/1 [01:00<00:00, 60.11s/it]\n",
            "raw matrix:             em\n",
            "answer_from    \n",
            "answer_type    \n",
            "             10\n",
            "\n",
            "detail em:              em\n",
            "answer_from     \n",
            "answer_type     \n",
            "             0.0\n",
            "\n",
            "detail f1:              f1\n",
            "answer_from     \n",
            "answer_type     \n",
            "             0.0\n",
            "\n",
            "global em:0.0\n",
            "\n",
            "global f1:0.0\n",
            "\n",
            "global scale:0.7\n",
            "\n",
            "global op:0.1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Output"
      ],
      "metadata": {
        "id": "_DV6UQLJkI0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ./outputs"
      ],
      "metadata": {
        "id": "pEcg9m8wm7Jg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8b76e2-51f6-4204-9677-e7ad59a10e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove './outputs': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.file_handling import write_output\n",
        "\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "write_output(tag_op_input, AlQA_pred, dataclass)\n",
        "AlQA_pred"
      ],
      "metadata": {
        "id": "pyKvVqFWkKTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "2aff5537-47ab-4408-dadd-7951cf047cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/HybridR/predictions.intermediate.json' -> 'outputs/predictions.intermediate.json'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ebe9999f370c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwrite_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_op_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlQA_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mAlQA_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/FinTabParse/utils/file_handling.py\u001b[0m in \u001b[0;36mwrite_output\u001b[0;34m(tag_op_input, AlQA, dataclass)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0mdict_to_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtagop_answers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs/tagop_answers.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/HybridR/predictions.intermediate.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'models/HybridR/predictions.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'outputs/hybridR_predictions.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0mhybridR_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_to_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'outputs/hybridR_predictions.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m             \u001b[0mcopy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models/HybridR/predictions.intermediate.json'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AlQA_pred"
      ],
      "metadata": {
        "id": "1N6qtdG3VnSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r outputs.zip ./outputs/"
      ],
      "metadata": {
        "id": "nHrDYP67XJmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TEST"
      ],
      "metadata": {
        "id": "WgD9QKtt1F95"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## chunking"
      ],
      "metadata": {
        "id": "m2Q7QrQRXopC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/FinTabParse/tests/test2/* /content/FinTabParse/inputs\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAzKhXQoKOU9",
        "outputId": "f6819d9b-4a12-437c-8ed7-760246651249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: -r not specified; omitting directory '/content/FinTabParse/tests/test2/outputs'\n",
            "cp: -r not specified; omitting directory '/content/FinTabParse/tests/test2/outputs2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.file_handling import read_inputs\n",
        "questions, paragraphs, table = read_inputs()"
      ],
      "metadata": {
        "id": "WDOLgW5MUGmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def perepare_chunk(table, row_chunk_no):\n",
        "  def add_header(chunk):\n",
        "    chunk.insert(0, table[0])\n",
        "    return chunk\n",
        "  \n",
        "  chunk_vals = range(row_chunk_no[-1]+1)\n",
        "  chunks = [[row for r, row in enumerate(table[1:]) if row_chunk_no[r]==x\n",
        "             ] for x in chunk_vals]\n",
        "  return list(map(add_header, chunks))\n",
        "\n",
        "def get_token_chunks(table, chunk_size=512):\n",
        "  header = table[0]\n",
        "  header_tokens = len(word_tokenize(' '.join(table[0])))\n",
        "  row_tokens = list(map(lambda row: len(word_tokenize(' '.join(row))), table[1:]))\n",
        "  cum_row_tokens = [sum(row_tokens[0:x:1])//(chunk_size-header_tokens) \n",
        "    for x in range(0, len(row_tokens)+1)]\n",
        "  row_chunk_no = cum_row_tokens[1:]\n",
        "  # chunk_vals = range(row_chunk_no[-1]+1)\n",
        "  # chunks = [[row for r, row in enumerate(table) if row_chunk_no[r]==x] for x in chunk_vals]\n",
        "             \n",
        "  return perepare_chunk(table, row_chunk_no)\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "ip1aEmFWRF7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = get_token_chunks(table, 512)"
      ],
      "metadata": {
        "id": "XbLAQW98Tf7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tapas"
      ],
      "metadata": {
        "id": "p8_P1a2OaXmI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "id": "EXlevM8iaZah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ec4dde-396b-4c0a-fcf3-eefc2587b827"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8.0 in /usr/local/lib/python3.7/dist-packages (2.8.0+zzzcolab20220506162203)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.21.6)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (3.1.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.46.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.25.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (14.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (4.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.8.0) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers"
      ],
      "metadata": {
        "id": "ISIaEVegoiIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "523e7e3b-9302-407e-fee2-66bb3bcceb76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.19.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "def json_to_dict(json_file):\n",
        "  with open(json_file, 'r') as f:\n",
        "    data = json.load(f)\n",
        "  return data\n",
        "\n",
        "def file_to_list(file_name):\n",
        "  \"\"\"\n",
        "  Reads a file and returns a list of lines\n",
        "  \"\"\"\n",
        "  with open(file_name, 'r') as f:\n",
        "    data = f.readlines()\n",
        "  return list(map(lambda x: x.replace('\\n', ''), data))\n",
        "\n",
        "def dict_to_json(tag_op_input, json_file):\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(tag_op_input, f)\n",
        "\n",
        "def list_to_file(list_data, file_name):\n",
        "  \"\"\"\n",
        "  Writes a list to a file\n",
        "  \"\"\"\n",
        "  with open(file_name, 'w') as f:\n",
        "    for line in list_data:\n",
        "      if(type(line)==type(\" \")):\n",
        "        f.write(line + '\\n')\n",
        "\n",
        "def get_inputs(questions_path, paragraphs_path, table_path):\n",
        "\tquestions = file_to_list(questions_path)\n",
        "\tparagraphs = file_to_list(paragraphs_path)\n",
        "\ttable = json_to_dict(table_path)\n",
        "\treturn questions, paragraphs, table\n",
        "\n",
        "def read_inputs():\n",
        "  inputs_path = './'\n",
        "  paragraphs_path = os.path.join(inputs_path, 'paragraphs.txt')\n",
        "  questions_path = os.path.join(inputs_path, 'questions.txt')\n",
        "  table_path = os.path.join(inputs_path, 'table.json')\n",
        "\n",
        "  questions, paragraphs, table = get_inputs(questions_path, paragraphs_path, table_path)\n",
        "  \n",
        "  return questions, paragraphs, table"
      ],
      "metadata": {
        "id": "Qg-WXVjl-xA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions, paragraphs, table = read_inputs()"
      ],
      "metadata": {
        "id": "2edmes5w-x_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "TaPaSQA = pd.DataFrame.from_records(table[1:], columns=table[0])"
      ],
      "metadata": {
        "id": "EbZAQ8q8adkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TapasTokenizer, TapasForQuestionAnswering\n",
        "\n",
        "def generate_outputs(table, queries):\n",
        "  # table = pd.DataFrame.from_dict(table_ip)\n",
        "  tokenizer = TapasTokenizer.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
        "  model = TapasForQuestionAnswering.from_pretrained(\"google/tapas-base-finetuned-wtq\")\n",
        "  inputs = tokenizer(table=table, queries=queries, padding=\"max_length\", return_tensors=\"tf\", truncation=True)\n",
        "  outputs = model(**inputs)\n",
        "  predicted_answer_coordinates, predicted_aggregation_indices = tokenizer.convert_logits_to_predictions(\n",
        "      inputs, outputs.logits, outputs.logits_aggregation\n",
        "  )\n",
        "  return (predicted_answer_coordinates, predicted_aggregation_indices)"
      ],
      "metadata": {
        "id": "B7C3529wb4lX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_outputs(TaPaSQA, questions)"
      ],
      "metadata": {
        "id": "gWDWX_09cbBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mMOu0wJIegee",
        "outputId": "8d7e3f92-c946-42da-960b-82ee965af2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uspsQDjpdE1Y",
        "outputId": "4ecee885-064c-4eec-89f5-cffb1708a7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.8.0\n",
            "  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (4.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (0.25.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.14.1)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (3.17.3)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 67.7 MB/s \n",
            "\u001b[?25hCollecting numpy>=1.20\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 42.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.8.0) (1.46.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.0) (0.37.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.0) (3.2.0)\n",
            "Installing collected packages: numpy, tf-estimator-nightly, tensorboard, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.4 requires scikit-learn>=1.0.0, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.23.2 which is incompatible.\n",
            "fbprophet 0.7.1 requires tqdm>=4.36.1, but you have tqdm 4.28.1 which is incompatible.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6 tensorboard-2.8.0 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}